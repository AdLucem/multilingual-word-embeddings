#+TITLE: Supervised Mapping of Word Embeddings: Testing

* Imports

First, we'll import Word2Vec from gensim, and also a few utility libraries.

#+NAME: imports
#+BEGIN_SRC python 
from gensim.models import KeyedVectors
import json
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import NearestNeighbors
import sys

#+END_SRC

We'll also import the =dataLoad= function from the =training= module.

#+NAME: local_imports
#+BEGIN_SRC python

from training import dataLoad

#+END_SRC

* Load the Model

Load the model (actually a list of models) from a joblib file.

#+NAME: load_models
#+BEGIN_SRC python

  from joblib import dump, load

  models = load("model.joblib")

#+END_SRC

* Testing

Now we actually implement the model, by:

(1) Finding the transform of the French source vector, according to the models trained.
(2) In the vector space of possible result english words (taken from the english test corpus), find the word with the least distance from this transformed vector. In other words, find the nearest neighbour of this vector.
(3) That word is the most likely translation of the root french word.

This is a naive algorithm that takes a lot of time, but we're doing it first to see if it works.

** Load The English Test Word Embeddings

#+NAME: get_eng_embeddings
#+BEGIN_SRC python
  tst_en = dataLoad("eng_test.json")

  # make a matrix of only the word embeddings
  # and an associated list of vocabulary

  en_vecs = []
  en_words = []
  for i in tst_en:
      en_words.append(i[0])
      en_vecs.append(i[1])

#+END_SRC

** Finding Transform of French Source Vector

#+NAME: find_transform_of_fr
#+BEGIN_SRC python


  tst_fr = dataLoad("fr_test.json")

  def find_transform(src):
   
      trans = []

      # loop to transform it
      for i in range(len(src)):
          a = models[i].coef_[0][0]
          b = models[i].intercept_[0]
          x = src[i]
          trans.append(a*x + b)

      return trans

#+END_SRC

** Finding Nearest Neighbour of Transformed Vector

#+NAME: nn_of_trans_vector
#+BEGIN_SRC python 

  def find_nn(trans):

      nbrs = NearestNeighbors(n_neighbors=1, algorithm='ball_tree').fit(en_vecs)
      distances, indices = nbrs.kneighbors([trans])

      index = indices[0][0]

      # remove that particular vector from the list
      # because the algorithm as current causes ALL french vectors
      # to translate to the english word 'collins'
      en_vecs.pop(index)
    
      word = en_words[index]
      return word
#+END_SRC

** Putting The Functions Together

#+NAME: test_loop
#+BEGIN_SRC python

  pairs = []

  for i in tst_fr:
      pair = []

      word = i[0]
      vec = i[1]
      pair.append(word)

      # get the transform
      trans = find_transform(vec)
      # get the translated word
      translation = find_nn(trans)

      pair.append(translation)

      pairs.append(pair)

  # now write it to file
  with open("results.json", "w+") as f:
      json.dump(pairs, f)

#+END_SRC

* Tangling

#+BEGIN_SRC python :eval no :noweb yes :tangle testing.py
<<imports>>
<<local_imports>>
<<load_models>>
<<get_eng_embeddings>>
<<find_transform_of_fr>>
<<nn_of_trans_vector>>
<<test_loop>>
#+END_SRC
